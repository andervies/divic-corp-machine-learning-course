{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78cd6cff",
   "metadata": {},
   "source": [
    "## Problem One: Confirmation of competition contents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5e3bc8",
   "metadata": {},
   "source": [
    "* What to learn and what to predict?\n",
    "\n",
    "* What kind of file to create and submit to Kaggle?\n",
    "\n",
    "* What kind of index value will be used to evaluate the submissions?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "What to learn and what to predict\n",
    "• To predict how capable each applicant is of repaying a loan\n",
    "What kind of file to create and submit to Kaggle?\n",
    "• A file predicting the probability for the TARGET variable. And should contain a header of both SK_ID_CURR and TARGET\n",
    "What kind of index value will be used to evaluate the submissions?\n",
    "• Submissions are evaluated on area under the ROC curve between the predicted probability and the observed target. The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection[8] in machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8857b8",
   "metadata": {},
   "source": [
    "## Problem Two: Learning and verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0850e161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import chi2_contingency\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "cd948d64",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>...</th>\n",
       "      <th>FLAG_DOCUMENT_18</th>\n",
       "      <th>FLAG_DOCUMENT_19</th>\n",
       "      <th>FLAG_DOCUMENT_20</th>\n",
       "      <th>FLAG_DOCUMENT_21</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_HOUR</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_DAY</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_WEEK</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_MON</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_QRT</th>\n",
       "      <th>AMT_REQ_CREDIT_BUREAU_YEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0</td>\n",
       "      <td>Revolving loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 122 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  TARGET NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR  \\\n",
       "0      100002       1         Cash loans           M            N   \n",
       "1      100003       0         Cash loans           F            N   \n",
       "2      100004       0    Revolving loans           M            Y   \n",
       "3      100006       0         Cash loans           F            N   \n",
       "4      100007       0         Cash loans           M            N   \n",
       "\n",
       "  FLAG_OWN_REALTY  CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0               Y             0          202500.0    406597.5      24700.5   \n",
       "1               N             0          270000.0   1293502.5      35698.5   \n",
       "2               Y             0           67500.0    135000.0       6750.0   \n",
       "3               Y             0          135000.0    312682.5      29686.5   \n",
       "4               Y             0          121500.0    513000.0      21865.5   \n",
       "\n",
       "   ...  FLAG_DOCUMENT_18 FLAG_DOCUMENT_19 FLAG_DOCUMENT_20 FLAG_DOCUMENT_21  \\\n",
       "0  ...                 0                0                0                0   \n",
       "1  ...                 0                0                0                0   \n",
       "2  ...                 0                0                0                0   \n",
       "3  ...                 0                0                0                0   \n",
       "4  ...                 0                0                0                0   \n",
       "\n",
       "  AMT_REQ_CREDIT_BUREAU_HOUR AMT_REQ_CREDIT_BUREAU_DAY  \\\n",
       "0                        0.0                       0.0   \n",
       "1                        0.0                       0.0   \n",
       "2                        0.0                       0.0   \n",
       "3                        NaN                       NaN   \n",
       "4                        0.0                       0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_WEEK  AMT_REQ_CREDIT_BUREAU_MON  \\\n",
       "0                         0.0                        0.0   \n",
       "1                         0.0                        0.0   \n",
       "2                         0.0                        0.0   \n",
       "3                         NaN                        NaN   \n",
       "4                         0.0                        0.0   \n",
       "\n",
       "   AMT_REQ_CREDIT_BUREAU_QRT  AMT_REQ_CREDIT_BUREAU_YEAR  \n",
       "0                        0.0                         1.0  \n",
       "1                        0.0                         0.0  \n",
       "2                        0.0                         0.0  \n",
       "3                        NaN                         NaN  \n",
       "4                        0.0                         0.0  \n",
       "\n",
       "[5 rows x 122 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "df_train = pd.read_csv(\"application_train.csv\")\n",
    "df_test = pd.read_csv(\"application_test.csv\")\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "664979f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Columns: 122 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(41), object(16)\n",
      "memory usage: 286.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48744 entries, 0 to 48743\n",
      "Columns: 121 entries, SK_ID_CURR to AMT_REQ_CREDIT_BUREAU_YEAR\n",
      "dtypes: float64(65), int64(40), object(16)\n",
      "memory usage: 45.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.info())\n",
    "display(df_test.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "761d2da9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 122)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(48744, 121)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.shape)\n",
    "display(df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f76c08",
   "metadata": {},
   "source": [
    "* The test dataset is missing the target column because target is the variable we're trying to predict.\n",
    "* We have 16 columns of data type object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9bd55f62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     67\n",
       "False    55\n",
       "dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_train.isna().sum() > 0).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c64da4bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AMT_ANNUITY', 'NAME_TYPE_SUITE', 'OWN_CAR_AGE', 'OCCUPATION_TYPE',\n",
       "       'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'APARTMENTS_AVG',\n",
       "       'BASEMENTAREA_AVG', 'YEARS_BEGINEXPLUATATION_AVG', 'YEARS_BUILD_AVG',\n",
       "       'COMMONAREA_AVG', 'ELEVATORS_AVG', 'ENTRANCES_AVG', 'FLOORSMAX_AVG',\n",
       "       'FLOORSMIN_AVG', 'LANDAREA_AVG', 'LIVINGAPARTMENTS_AVG',\n",
       "       'LIVINGAREA_AVG', 'NONLIVINGAPARTMENTS_AVG', 'NONLIVINGAREA_AVG',\n",
       "       'APARTMENTS_MODE', 'BASEMENTAREA_MODE', 'YEARS_BEGINEXPLUATATION_MODE',\n",
       "       'YEARS_BUILD_MODE', 'COMMONAREA_MODE', 'ELEVATORS_MODE',\n",
       "       'ENTRANCES_MODE', 'FLOORSMAX_MODE', 'FLOORSMIN_MODE', 'LANDAREA_MODE',\n",
       "       'LIVINGAPARTMENTS_MODE', 'LIVINGAREA_MODE', 'NONLIVINGAPARTMENTS_MODE',\n",
       "       'NONLIVINGAREA_MODE', 'APARTMENTS_MEDI', 'BASEMENTAREA_MEDI',\n",
       "       'YEARS_BEGINEXPLUATATION_MEDI', 'YEARS_BUILD_MEDI', 'COMMONAREA_MEDI',\n",
       "       'ELEVATORS_MEDI', 'ENTRANCES_MEDI', 'FLOORSMAX_MEDI', 'FLOORSMIN_MEDI',\n",
       "       'LANDAREA_MEDI', 'LIVINGAPARTMENTS_MEDI', 'LIVINGAREA_MEDI',\n",
       "       'NONLIVINGAPARTMENTS_MEDI', 'NONLIVINGAREA_MEDI', 'FONDKAPREMONT_MODE',\n",
       "       'HOUSETYPE_MODE', 'TOTALAREA_MODE', 'WALLSMATERIAL_MODE',\n",
       "       'EMERGENCYSTATE_MODE', 'OBS_30_CNT_SOCIAL_CIRCLE',\n",
       "       'DEF_30_CNT_SOCIAL_CIRCLE', 'OBS_60_CNT_SOCIAL_CIRCLE',\n",
       "       'DEF_60_CNT_SOCIAL_CIRCLE', 'AMT_REQ_CREDIT_BUREAU_HOUR',\n",
       "       'AMT_REQ_CREDIT_BUREAU_DAY', 'AMT_REQ_CREDIT_BUREAU_WEEK',\n",
       "       'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n",
       "       'AMT_REQ_CREDIT_BUREAU_YEAR'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns[(df_test.isna().sum() > 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "dace4bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check the correlation between a quantitative variable and the target\n",
    "def compare_corr(features):\n",
    "    features.append(\"TARGET\")\n",
    "    return df_train[features].corr()\n",
    "\n",
    "\n",
    "def compute_chi(cat_variable):\n",
    "    \"\"\"\n",
    "    Function to compute the correlation of a categorical variable and the target\n",
    "    \"\"\"\n",
    "    # Create a contingency table\n",
    "    contingency_table = pd.crosstab(df_train[cat_variable], df_train[\"TARGET\"])\n",
    "\n",
    "    # Calculate the chi-square statistic and p-value\n",
    "    chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "    # Print the results\n",
    "    print(\"Chi-square statistic:\", chi2)\n",
    "    print(\"p-value:\", p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8a70de88",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIVINGAPARTMENTS_MODE           68.354953\n",
       "LIVINGAPARTMENTS_MEDI           68.354953\n",
       "LIVINGAPARTMENTS_AVG            68.354953\n",
       "FLOORSMIN_MODE                  67.848630\n",
       "FLOORSMIN_MEDI                  67.848630\n",
       "FLOORSMIN_AVG                   67.848630\n",
       "YEARS_BUILD_MODE                66.497784\n",
       "YEARS_BUILD_MEDI                66.497784\n",
       "YEARS_BUILD_AVG                 66.497784\n",
       "OWN_CAR_AGE                     65.990810\n",
       "LANDAREA_AVG                    59.376738\n",
       "LANDAREA_MEDI                   59.376738\n",
       "LANDAREA_MODE                   59.376738\n",
       "BASEMENTAREA_MEDI               58.515956\n",
       "BASEMENTAREA_AVG                58.515956\n",
       "BASEMENTAREA_MODE               58.515956\n",
       "EXT_SOURCE_1                    56.381073\n",
       "NONLIVINGAREA_MEDI              55.179164\n",
       "NONLIVINGAREA_MODE              55.179164\n",
       "NONLIVINGAREA_AVG               55.179164\n",
       "ELEVATORS_MEDI                  53.295980\n",
       "ELEVATORS_MODE                  53.295980\n",
       "ELEVATORS_AVG                   53.295980\n",
       "WALLSMATERIAL_MODE              50.840783\n",
       "APARTMENTS_MODE                 50.749729\n",
       "APARTMENTS_MEDI                 50.749729\n",
       "APARTMENTS_AVG                  50.749729\n",
       "ENTRANCES_MODE                  50.348768\n",
       "ENTRANCES_AVG                   50.348768\n",
       "ENTRANCES_MEDI                  50.348768\n",
       "LIVINGAREA_MEDI                 50.193326\n",
       "LIVINGAREA_MODE                 50.193326\n",
       "LIVINGAREA_AVG                  50.193326\n",
       "HOUSETYPE_MODE                  50.176091\n",
       "FLOORSMAX_MEDI                  49.760822\n",
       "FLOORSMAX_AVG                   49.760822\n",
       "FLOORSMAX_MODE                  49.760822\n",
       "YEARS_BEGINEXPLUATATION_AVG     48.781019\n",
       "YEARS_BEGINEXPLUATATION_MEDI    48.781019\n",
       "YEARS_BEGINEXPLUATATION_MODE    48.781019\n",
       "TOTALAREA_MODE                  48.268517\n",
       "EMERGENCYSTATE_MODE             47.398304\n",
       "OCCUPATION_TYPE                 31.345545\n",
       "EXT_SOURCE_3                    19.825307\n",
       "AMT_REQ_CREDIT_BUREAU_WEEK      13.501631\n",
       "AMT_REQ_CREDIT_BUREAU_DAY       13.501631\n",
       "AMT_REQ_CREDIT_BUREAU_MON       13.501631\n",
       "AMT_REQ_CREDIT_BUREAU_QRT       13.501631\n",
       "AMT_REQ_CREDIT_BUREAU_HOUR      13.501631\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR      13.501631\n",
       "NAME_TYPE_SUITE                  0.420148\n",
       "DEF_30_CNT_SOCIAL_CIRCLE         0.332021\n",
       "OBS_60_CNT_SOCIAL_CIRCLE         0.332021\n",
       "DEF_60_CNT_SOCIAL_CIRCLE         0.332021\n",
       "OBS_30_CNT_SOCIAL_CIRCLE         0.332021\n",
       "EXT_SOURCE_2                     0.214626\n",
       "AMT_GOODS_PRICE                  0.090403\n",
       "AMT_ANNUITY                      0.003902\n",
       "CNT_FAM_MEMBERS                  0.000650\n",
       "DAYS_LAST_PHONE_CHANGE           0.000325\n",
       "dtype: float64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the percentage of missing values in the train dataset\n",
    "\n",
    "percent_missing_train = df_train.isna().sum() / len(df_train) * 100\n",
    "\n",
    "col_missing_train = df_train.columns[(percent_missing_train != 0)]\n",
    "\n",
    "percent_missing_train[percent_missing_train > 0].sort_values(ascending=False).tail(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794d385b",
   "metadata": {},
   "source": [
    "Most of the features with missing values are related with the building or home of the client, we will investigate their individual correlation with the target later on. For now, my hypothesis is that there should be some relationship between the OCCUPATION_TYPE feature and the rate of default, so we shall test this theory in order to decide if to bother with imputation of missing variables for OCCUPATION_TYPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "80bd8830",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OCCUPATION_TYPE\n",
       "Accountants              0.95\n",
       "Core staff               0.94\n",
       "HR staff                 0.94\n",
       "High skill tech staff    0.94\n",
       "IT staff                 0.94\n",
       "Managers                 0.94\n",
       "Secretaries              0.93\n",
       "Medicine staff           0.93\n",
       "Private service staff    0.93\n",
       "Realty agents            0.92\n",
       "Sales staff              0.90\n",
       "Cooking staff            0.90\n",
       "Cleaning staff           0.90\n",
       "Security staff           0.89\n",
       "Waiters/barmen staff     0.89\n",
       "Laborers                 0.89\n",
       "Drivers                  0.89\n",
       "Low-skill Laborers       0.83\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if there's any relationship between OCCUPATION_TYPE and rate of repayment\n",
    "(1 - df_train.groupby(\"OCCUPATION_TYPE\").mean().round(2)[\"TARGET\"]).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbde6ca",
   "metadata": {},
   "source": [
    "We can see that there is some change in the data as we move from corporate jobs to manual jobs, this information might be useful for our model, so we shall try to fill in the missing values OCCUPATION_TYPE and further investigate if it has any impact on our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d359d5b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET    0.934869\n",
       "dtype: float64"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the rate of repayment for clients with missing occupation types\n",
    "1 - df_train[df_train.OCCUPATION_TYPE.isna()][[\"TARGET\"]].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9b251110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 1402.8467961927515\n",
      "p-value: 3.7844998567642684e-288\n"
     ]
    }
   ],
   "source": [
    "compute_chi(\"OCCUPATION_TYPE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "00dfdc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing the missing values in OCCUPATION_TYPE with the most frequent observation\n",
    "most_frequent_occupation = df_train[\"OCCUPATION_TYPE\"].mode().iloc[0]\n",
    "\n",
    "# Replace missing values with the most frequent occupation\n",
    "df_train[\"OCCUPATION_TYPE\"].fillna(most_frequent_occupation, inplace=True)\n",
    "df_test[\"OCCUPATION_TYPE\"].fillna(df_test[\"OCCUPATION_TYPE\"].mode().iloc[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8dca208b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-square statistic: 1193.3947394399675\n",
      "p-value: 3.4203518801583733e-243\n"
     ]
    }
   ],
   "source": [
    "# Checking if the imputation drastically affects the correlation between OCCUPATION_TYPE and the target \n",
    "compute_chi(\"OCCUPATION_TYPE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2e45e0",
   "metadata": {},
   "source": [
    "There is only a slight decrease in correlation between the two variables after mode imputation so we shall accept this imputation technique and also keep OCCUPATION_TYPE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "aeea6536",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TARGET                          1.000000\n",
       "EXT_SOURCE_3                    0.178919\n",
       "EXT_SOURCE_2                    0.160472\n",
       "EXT_SOURCE_1                    0.155317\n",
       "DAYS_LAST_PHONE_CHANGE          0.055218\n",
       "FLOORSMAX_AVG                   0.044003\n",
       "FLOORSMAX_MEDI                  0.043768\n",
       "FLOORSMAX_MODE                  0.043226\n",
       "AMT_GOODS_PRICE                 0.039645\n",
       "OWN_CAR_AGE                     0.037612\n",
       "ELEVATORS_AVG                   0.034199\n",
       "ELEVATORS_MEDI                  0.033863\n",
       "FLOORSMIN_AVG                   0.033614\n",
       "FLOORSMIN_MEDI                  0.033394\n",
       "LIVINGAREA_AVG                  0.032997\n",
       "LIVINGAREA_MEDI                 0.032739\n",
       "FLOORSMIN_MODE                  0.032698\n",
       "TOTALAREA_MODE                  0.032596\n",
       "DEF_30_CNT_SOCIAL_CIRCLE        0.032248\n",
       "ELEVATORS_MODE                  0.032131\n",
       "DEF_60_CNT_SOCIAL_CIRCLE        0.031276\n",
       "LIVINGAREA_MODE                 0.030685\n",
       "APARTMENTS_AVG                  0.029498\n",
       "APARTMENTS_MEDI                 0.029184\n",
       "APARTMENTS_MODE                 0.027284\n",
       "LIVINGAPARTMENTS_AVG            0.025031\n",
       "LIVINGAPARTMENTS_MEDI           0.024621\n",
       "LIVINGAPARTMENTS_MODE           0.023393\n",
       "BASEMENTAREA_AVG                0.022746\n",
       "YEARS_BUILD_MEDI                0.022326\n",
       "YEARS_BUILD_AVG                 0.022149\n",
       "BASEMENTAREA_MEDI               0.022081\n",
       "YEARS_BUILD_MODE                0.022068\n",
       "BASEMENTAREA_MODE               0.019952\n",
       "AMT_REQ_CREDIT_BUREAU_YEAR      0.019930\n",
       "ENTRANCES_AVG                   0.019172\n",
       "ENTRANCES_MEDI                  0.019025\n",
       "COMMONAREA_MEDI                 0.018573\n",
       "COMMONAREA_AVG                  0.018550\n",
       "ENTRANCES_MODE                  0.017387\n",
       "COMMONAREA_MODE                 0.016340\n",
       "NONLIVINGAREA_AVG               0.013578\n",
       "NONLIVINGAREA_MEDI              0.013337\n",
       "AMT_ANNUITY                     0.012817\n",
       "NONLIVINGAREA_MODE              0.012711\n",
       "AMT_REQ_CREDIT_BUREAU_MON       0.012462\n",
       "LANDAREA_MEDI                   0.011256\n",
       "LANDAREA_AVG                    0.010885\n",
       "LANDAREA_MODE                   0.010174\n",
       "YEARS_BEGINEXPLUATATION_MEDI    0.009993\n",
       "YEARS_BEGINEXPLUATATION_AVG     0.009728\n",
       "CNT_FAM_MEMBERS                 0.009308\n",
       "OBS_30_CNT_SOCIAL_CIRCLE        0.009131\n",
       "YEARS_BEGINEXPLUATATION_MODE    0.009036\n",
       "OBS_60_CNT_SOCIAL_CIRCLE        0.009022\n",
       "NONLIVINGAPARTMENTS_AVG         0.003176\n",
       "NONLIVINGAPARTMENTS_MEDI        0.002757\n",
       "AMT_REQ_CREDIT_BUREAU_DAY       0.002704\n",
       "AMT_REQ_CREDIT_BUREAU_QRT       0.002022\n",
       "NONLIVINGAPARTMENTS_MODE        0.001557\n",
       "Name: TARGET, dtype: float64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting and displaying the correlation of all missing variables and the target\n",
    "missing_val_corr = compare_corr(percent_missing_train[percent_missing_train != 0].index.to_list())\n",
    "\n",
    "# We take the absolute values of the correlation coefficients to account for negative correlation\n",
    "missing_val_corr.TARGET.apply(lambda x: abs(x)).sort_values(ascending=False).head(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef0f021",
   "metadata": {},
   "source": [
    "Most of the features have very poor correlation power. We shall only consider EXT_SOURCE_3, EXT_SOURCE_2, and EXT_SOURCE_1 because although they have poor correlation with the target, their correlation coefficients surpass all other features, and domain knowledge suggests that external sources play a huge role in credit allocation.\n",
    "\n",
    "**Feature Engineering Approach:** We shall take the mean the values of all three variables and see how that affects the predictive power of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "f4db1a74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EXT_SOURCE_MEAN</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>EXT_SOURCE_MEAN</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.222052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TARGET</th>\n",
       "      <td>-0.222052</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 EXT_SOURCE_MEAN    TARGET\n",
       "EXT_SOURCE_MEAN         1.000000 -0.222052\n",
       "TARGET                 -0.222052  1.000000"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handling missing data in EXT_SOURCE_3, EXT_SOURCE_2, and EXT_SOURCE_1\n",
    "\n",
    "df_train[\"EXT_SOURCE_MEAN\"] = df_train[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].mean(axis=1)\n",
    "df_test[\"EXT_SOURCE_MEAN\"] = df_test[[\"EXT_SOURCE_1\", \"EXT_SOURCE_2\", \"EXT_SOURCE_3\"]].mean(axis=1)\n",
    "\n",
    "df_train[[\"EXT_SOURCE_MEAN\", \"TARGET\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9009eb8",
   "metadata": {},
   "source": [
    "The result of the correlation between EXT_SOURCE_MEAN, which is the mean of EXT_SOURCE_1, EXT_SOURCE_2, and EXT_SOURCE_3, and TARGET show an inverse increament when compared to the correlation between TARGET and each individual feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "33ad2515",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_to_drop = [col for col in col_missing_train if col != \"OCCUPATION_TYPE\"]\n",
    "len(features_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "87f333e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c8f82315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_CURR', 'TARGET', 'NAME_CONTRACT_TYPE', 'CODE_GENDER',\n",
       "       'FLAG_OWN_CAR', 'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL',\n",
       "       'AMT_CREDIT', 'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE',\n",
       "       'NAME_FAMILY_STATUS', 'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE',\n",
       "       'DAYS_BIRTH', 'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH',\n",
       "       'FLAG_MOBIL', 'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE',\n",
       "       'FLAG_PHONE', 'FLAG_EMAIL', 'OCCUPATION_TYPE', 'REGION_RATING_CLIENT',\n",
       "       'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START',\n",
       "       'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION',\n",
       "       'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION',\n",
       "       'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY',\n",
       "       'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'FLAG_DOCUMENT_2',\n",
       "       'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5',\n",
       "       'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8',\n",
       "       'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11',\n",
       "       'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n",
       "       'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17',\n",
       "       'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20',\n",
       "       'FLAG_DOCUMENT_21', 'EXT_SOURCE_MEAN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dropping features\n",
    "df_train.drop(features_to_drop, axis=1, inplace=True)\n",
    "df_test.drop(features_to_drop, axis=1, inplace=True)\n",
    "percent_missing_train.drop(features_to_drop, inplace=True)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "59f4cc4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57 56\n"
     ]
    }
   ],
   "source": [
    "print(len(df_train.columns), len(df_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a4a08",
   "metadata": {},
   "source": [
    "Train dataset still has its target column, we shall extract that in a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cacd63af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a LabelEncoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "obj_cols = df_train.columns[df_train.dtypes == \"object\"]\n",
    "\n",
    "# Encoding all features of object type \n",
    "for i in obj_cols:\n",
    "    df_train[i] = le.fit_transform(df_train[i])\n",
    "    df_test[i] = le.fit_transform(df_test[i])\n",
    "    \n",
    "# Checking that all object data type have been encoded\n",
    "len(df_train.select_dtypes(\"object\").columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae8897b",
   "metadata": {},
   "source": [
    "We've succeeded in filling the missing values and encoding the columns of data type object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "4e1474f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EXT_SOURCE_MEAN'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['EXT_SOURCE_MEAN'], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_train.columns[df_train.isna().sum() > 0])\n",
    "display(df_test.columns[df_test.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6c33de99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing the few missing values in EXT_SOURCE_MEAN with the entire feature's mean\n",
    "df_train.EXT_SOURCE_MEAN.fillna(df_train[\"EXT_SOURCE_MEAN\"].mean(), inplace=True)\n",
    "df_test.EXT_SOURCE_MEAN.fillna(df_test[\"EXT_SOURCE_MEAN\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d0ddd645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confirming that there is no missing values in the dataset\n",
    "display(df_train.columns[df_train.isna().sum() > 0])\n",
    "display(df_test.columns[df_test.isna().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f05b46",
   "metadata": {},
   "source": [
    "### Training and Evaluation of Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7479ca9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = df_train.drop([\"SK_ID_CURR\", \"TARGET\"], axis=1)\n",
    "y = df_train[\"TARGET\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_transformed = scaler.fit_transform(X_train)\n",
    "X_test_transformed = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40acdee0",
   "metadata": {},
   "source": [
    "SK_ID_CURR was dropped because it poses the risk of data leakage. Including it in the model could leak information about past applications for the same borrower, violating the assumption that data points in the test set are independent and unseen by the model during training. This can lead to inflated accuracy and misleading generalization performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0eb13fb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC for Decision Tree is 0.5369579454921836\n",
      "Accuracy for Decision Tree is 0.848942480293452\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Random Forest is 0.5003472244938048\n",
      "Accuracy for Random Forest is 0.9194307864408543\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Logistic Regression is 0.5019359690416059\n",
      "Accuracy for Logistic Regression is 0.9192356721038528\n"
     ]
    }
   ],
   "source": [
    "# Training the baseline models\n",
    "dtree = DecisionTreeClassifier()\n",
    "dtree.fit(X_train_transformed, y_train)\n",
    "y_pred_dtree = dtree.predict(X_test_transformed)\n",
    "print(f\"ROC for Decision Tree is {roc_auc_score(y_test, y_pred_dtree)}\")\n",
    "print(f\"Accuracy for Decision Tree is {accuracy_score(y_test, y_pred_dtree)}\\n\\n\")\n",
    "\n",
    "\n",
    "rand_forest = RandomForestClassifier()\n",
    "rand_forest.fit(X_train_transformed, y_train)\n",
    "y_pred_rf = rand_forest.predict(X_test_transformed)\n",
    "print(\"-\" * 100)\n",
    "print(f\"ROC for Random Forest is {roc_auc_score(y_test, y_pred_rf)}\")\n",
    "print(f\"Accuracy for Random Forest is {accuracy_score(y_test, y_pred_rf)}\\n\\n\")\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_transformed, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_transformed)\n",
    "print(\"-\" * 100)\n",
    "print(f\"ROC for Logistic Regression is {roc_auc_score(y_test, y_pred_log_reg)}\")\n",
    "print(f\"Accuracy for Logistic Regression is {accuracy_score(y_test, y_pred_log_reg)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef9d408",
   "metadata": {},
   "source": [
    "All models have very low ROC AUC values and high accuracy values, this contrast can be explained by the imbalance of the classes in the dataset. Whilst Decision Tree has the highest ROC AUC value, if we consider its accuracy score, we can infer that it may prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae565995",
   "metadata": {},
   "source": [
    "## Problem Three: Estimation on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "86e9da65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scaled_test_data = scaler.transform(df_test.drop(\"SK_ID_CURR\", axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "f59b2183",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_test = rand_forest.predict(scaled_test_data)\n",
    "pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "b4d43799",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[\"TARGET\"] = pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "f1fc25c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48739</th>\n",
       "      <td>456221</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48740</th>\n",
       "      <td>456222</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48741</th>\n",
       "      <td>456223</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48742</th>\n",
       "      <td>456224</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48743</th>\n",
       "      <td>456250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48744 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       SK_ID_CURR  TARGET\n",
       "0          100001       0\n",
       "1          100005       0\n",
       "2          100013       0\n",
       "3          100028       0\n",
       "4          100038       0\n",
       "...           ...     ...\n",
       "48739      456221       0\n",
       "48740      456222       0\n",
       "48741      456223       0\n",
       "48742      456224       0\n",
       "48743      456250       0\n",
       "\n",
       "[48744 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_01 = df_test[[\"SK_ID_CURR\", \"TARGET\"]]\n",
    "submit_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c494fdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_01.to_csv(\"submit_01.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191ae323",
   "metadata": {},
   "source": [
    "## Problem Four: Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "75b3c9bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EXT_SOURCE_MEAN', 'DAYS_BIRTH', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION',\n",
       "       'DAYS_EMPLOYED', 'AMT_CREDIT', 'REGION_POPULATION_RELATIVE',\n",
       "       'AMT_INCOME_TOTAL', 'HOUR_APPR_PROCESS_START', 'ORGANIZATION_TYPE',\n",
       "       'WEEKDAY_APPR_PROCESS_START', 'OCCUPATION_TYPE', 'NAME_FAMILY_STATUS',\n",
       "       'CNT_CHILDREN', 'NAME_HOUSING_TYPE', 'NAME_INCOME_TYPE', 'FLAG_PHONE',\n",
       "       'FLAG_OWN_REALTY', 'FLAG_WORK_PHONE', 'REGION_RATING_CLIENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = pd.DataFrame(dtree.feature_importances_, index=X.columns).sort_values(0, ascending=False)[:20].index\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "20c90523",
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = df_train[selected_features[:2]]\n",
    "x2 = df_train[selected_features[:4]]\n",
    "x3 = df_train[selected_features[:8]]\n",
    "x4 = df_train[selected_features[:10]]\n",
    "x5 = df_train[selected_features[:16]]\n",
    "x6 = df_train[selected_features[:20]]\n",
    "x7 = df_train[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "9734b74f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for x1 is 0.5106027864147802\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for x2 is 0.5056399350037227\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for x3 is 0.5022761200989937\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for x4 is 0.5017532239382994\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for x5 is 0.5010628937906647\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for x6 is 0.5008247254395555\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for x7 is 0.5006944489876094\n"
     ]
    }
   ],
   "source": [
    "def feat_train(X, var_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_transformed = scaler.fit_transform(X_train)\n",
    "    X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    rand_forest = RandomForestClassifier()\n",
    "    rand_forest.fit(X_train_transformed, y_train)\n",
    "    y_pred_rf = rand_forest.predict(X_test_transformed)\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"ROC for {var_name} is {roc_auc_score(y_test, y_pred_rf)}\")\n",
    "\n",
    "feature_dict = {\"x1\": x1, \"x2\": x2, \"x3\": x3, \"x4\": x4, \"x5\": x5, \"x6\": x6, \"x7\": x7}\n",
    "\n",
    "for key in feature_dict:\n",
    "    feat_train(feature_dict[key], key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908fef86",
   "metadata": {},
   "source": [
    "I made several subsets of the train dataset based on features of high importance according to the Decision Tree module and trained evaluated the impact of each feature subset on our baseline model. This gives us clues on the features wielding higher predictive power. We can see that the ROC AUC of the model decreases with the addition of each subset, with our engineered feature, EXT_SOURCE_MEAN, showing a lot of promise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "4a8e6033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_train(X, var_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_transformed = scaler.fit_transform(X_train)\n",
    "    X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    dtree = DecisionTreeClassifier()\n",
    "    dtree.fit(X_train_transformed, y_train)\n",
    "    y_pred_rf = dtree.predict(X_test_transformed)\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"ROC for {var_name} is {roc_auc_score(y_test, y_pred_rf)}\")\n",
    "    \n",
    "    \n",
    "for key in feature_dict:\n",
    "    feat_train(feature_dict[key], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecd7362d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for EXT_SOURCE_MEAN is 0.5290996524071528\n"
     ]
    }
   ],
   "source": [
    "# Confirming that EXT_SOURCE_MEAN is has a positive impact on the model\n",
    "feat_train(df_train[selected_features[:1]], \"EXT_SOURCE_MEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "43c47421",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_m/l886rtzn5qg4bpvjp2ln5wk80000gn/T/ipykernel_8055/1189675016.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeat_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"x1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_m/l886rtzn5qg4bpvjp2ln5wk80000gn/T/ipykernel_8055/366922502.py\u001b[0m in \u001b[0;36mfeat_train\u001b[0;34m(X, var_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mrand_forest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrand_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_transformed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0my_pred_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrand_forest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_transformed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    448\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 450\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1046\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1047\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    859\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    860\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 861\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    862\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    777\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"balanced\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    935\u001b[0m         \"\"\"\n\u001b[1;32m    936\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 937\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    938\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    939\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    418\u001b[0m             )\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "feat_train(x1, \"x1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5cffc78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['EXT_SOURCE_MEAN', 'DAYS_BIRTH', 'DAYS_ID_PUBLISH', 'DAYS_REGISTRATION',\n",
       "       'DAYS_EMPLOYED', 'AMT_CREDIT', 'REGION_POPULATION_RELATIVE',\n",
       "       'AMT_INCOME_TOTAL', 'HOUR_APPR_PROCESS_START', 'ORGANIZATION_TYPE',\n",
       "       'WEEKDAY_APPR_PROCESS_START', 'OCCUPATION_TYPE', 'NAME_FAMILY_STATUS',\n",
       "       'CNT_CHILDREN', 'NAME_HOUSING_TYPE', 'NAME_INCOME_TYPE', 'FLAG_PHONE',\n",
       "       'FLAG_OWN_REALTY', 'FLAG_WORK_PHONE', 'REGION_RATING_CLIENT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7627a1e1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['SK_ID_CURR', 'NAME_CONTRACT_TYPE', 'CODE_GENDER', 'FLAG_OWN_CAR',\n",
       "       'FLAG_OWN_REALTY', 'CNT_CHILDREN', 'AMT_INCOME_TOTAL', 'AMT_CREDIT',\n",
       "       'NAME_INCOME_TYPE', 'NAME_EDUCATION_TYPE', 'NAME_FAMILY_STATUS',\n",
       "       'NAME_HOUSING_TYPE', 'REGION_POPULATION_RELATIVE', 'DAYS_BIRTH',\n",
       "       'DAYS_EMPLOYED', 'DAYS_REGISTRATION', 'DAYS_ID_PUBLISH', 'FLAG_MOBIL',\n",
       "       'FLAG_EMP_PHONE', 'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE', 'FLAG_PHONE',\n",
       "       'FLAG_EMAIL', 'OCCUPATION_TYPE', 'REGION_RATING_CLIENT',\n",
       "       'REGION_RATING_CLIENT_W_CITY', 'WEEKDAY_APPR_PROCESS_START',\n",
       "       'HOUR_APPR_PROCESS_START', 'REG_REGION_NOT_LIVE_REGION',\n",
       "       'REG_REGION_NOT_WORK_REGION', 'LIVE_REGION_NOT_WORK_REGION',\n",
       "       'REG_CITY_NOT_LIVE_CITY', 'REG_CITY_NOT_WORK_CITY',\n",
       "       'LIVE_CITY_NOT_WORK_CITY', 'ORGANIZATION_TYPE', 'FLAG_DOCUMENT_2',\n",
       "       'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5',\n",
       "       'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8',\n",
       "       'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11',\n",
       "       'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14',\n",
       "       'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17',\n",
       "       'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20',\n",
       "       'FLAG_DOCUMENT_21', 'EXT_SOURCE_MEAN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Feature Engineering\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "99b13466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3', 'FLAG_DOCUMENT_4',\n",
       "       'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6', 'FLAG_DOCUMENT_7',\n",
       "       'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9', 'FLAG_DOCUMENT_10',\n",
       "       'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12', 'FLAG_DOCUMENT_13',\n",
       "       'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15', 'FLAG_DOCUMENT_16',\n",
       "       'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18', 'FLAG_DOCUMENT_19',\n",
       "       'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[\"FLAG_DOCUMENT\"] = X[X.columns[35:55]].sum(axis=1)\n",
    "X.drop(X[X.columns[35:55]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "1fe7eb4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Logistic Regression is 0.5\n",
      "Accuracy for Logistic Regression is 0.9194698093082546\n",
      "ROC for x1 is 0.5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Logistic Regression is 0.5000595420877774\n",
      "Accuracy for Logistic Regression is 0.9194437940633211\n",
      "ROC for x2 is 0.5000595420877774\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Logistic Regression is 0.5\n",
      "Accuracy for Logistic Regression is 0.9194698093082546\n",
      "ROC for x3 is 0.5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Logistic Regression is 0.5\n",
      "Accuracy for Logistic Regression is 0.9194698093082546\n",
      "ROC for x4 is 0.5\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Logistic Regression is 0.5000595420877774\n",
      "Accuracy for Logistic Regression is 0.9194437940633211\n",
      "ROC for x5 is 0.5000595420877774\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Logistic Regression is 0.5001403044848053\n",
      "Accuracy for Logistic Regression is 0.9194568016857879\n",
      "ROC for x6 is 0.5001403044848053\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ROC for Logistic Regression is 0.5001403044848053\n",
      "Accuracy for Logistic Regression is 0.9194568016857879\n",
      "ROC for x7 is 0.5001403044848053\n"
     ]
    }
   ],
   "source": [
    "def feat_train(X, var_name):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_transformed = scaler.fit_transform(X_train)\n",
    "    X_test_transformed = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train_transformed, y_train)\n",
    "    y_pred_log_reg = log_reg.predict(X_test_transformed)\n",
    "    print(\"-\" * 100)\n",
    "    print(f\"ROC for Logistic Regression is {roc_auc_score(y_test, y_pred_log_reg)}\")\n",
    "    print(f\"Accuracy for Logistic Regression is {accuracy_score(y_test, y_pred_log_reg)}\")\n",
    "    print(f\"ROC for {var_name} is {roc_auc_score(y_test, y_pred_log_reg)}\")\n",
    "\n",
    "df_train[\"FLAG_DOCUMENT\"] = df_train[df_train.columns[35:55]].sum(axis=1)\n",
    "df_test[\"FLAG_DOCUMENT\"] = df_test[df_test.columns[35:55]].sum(axis=1)\n",
    "\n",
    "feature_dict = {\"x1\": x1, \"x2\": x2, \"x3\": x3, \"x4\": x4, \"x5\": x5, \"x6\": x6, \"x7\": x7}\n",
    "\n",
    "\n",
    "for key in feature_dict:\n",
    "    feat_train(feature_dict[key], key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0671393e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
